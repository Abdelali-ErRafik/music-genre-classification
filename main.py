#!/usr/bin/env python3
"""
Classification des Genres Musicaux - Script Principal
=====================================================

Ce script ex√©cute le pipeline complet de classification des genres musicaux:
1. Chargement des donn√©es
2. Extraction des caract√©ristiques audio
3. Entra√Ænement des mod√®les
4. √âvaluation et visualisation des r√©sultats

Usage:
    python main.py                    # Pipeline complet
    python main.py --step extract     # Extraction des features uniquement
    python main.py --step train       # Entra√Ænement uniquement
    python main.py --step evaluate    # √âvaluation uniquement
    python main.py --help             # Aide

Auteur: Votre √âquipe
Date: 2026
"""

import argparse
import sys
from pathlib import Path

# Ajouter le r√©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent))

from src.config import Config
from src.data_loader import DataLoader
from src.feature_extraction import FeatureExtractor
from src.visualization import Visualizer
from src.models import ModelTrainer
from src.evaluation import Evaluator
from src.utils import print_header, print_section, Timer, check_dependencies, set_random_seed


def step_extract_features():
    """
    √âtape 1: Extraction des caract√©ristiques audio.
    """
    print_header("√âTAPE 1: EXTRACTION DES CARACT√âRISTIQUES")
    
    # Charger les donn√©es
    print_section("Chargement des donn√©es")
    loader = DataLoader()
    df = loader.scan_dataset()
    
    if len(df) == 0:
        print("‚ùå Aucun fichier audio trouv√©!")
        print(f"   Veuillez placer les fichiers dans: {Config.DATA_RAW}")
        print("   Structure attendue: data/raw/genre/fichier.wav")
        return None
    
    loader.print_dataset_summary(df)
    
    # Extraire les features
    print_section("Extraction des features")
    extractor = FeatureExtractor()
    extractor.print_feature_summary()
    
    features_path = Config.DATA_PROCESSED / Config.FEATURES_FILE
    
    with Timer("Extraction des caract√©ristiques"):
        features_df = extractor.extract_features_from_dataset(
            df, 
            save_path=features_path
        )
    
    return features_df


def step_visualize(features_df):
    """
    √âtape 2: Visualisation des donn√©es.
    """
    print_header("√âTAPE 2: VISUALISATION DES DONN√âES")
    
    visualizer = Visualizer()
    
    # Distribution des genres
    print_section("Distribution des genres")
    visualizer.plot_genre_distribution(features_df, save_name="genre_distribution.png")
    
    # Visualisation de quelques features importantes
    print_section("Distribution des caract√©ristiques")
    important_features = [
        'spectral_centroid_mean',
        'tempo',
        'zero_crossing_rate_mean',
        'mfcc_1_mean'
    ]
    
    for feature in important_features:
        if feature in features_df.columns:
            visualizer.plot_feature_distribution(
                features_df, 
                feature,
                save_name=f"dist_{feature}.png"
            )
    
    # Matrice de corr√©lation
    print_section("Matrice de corr√©lation")
    visualizer.plot_correlation_matrix(features_df, save_name="correlation_matrix.png")
    
    # PCA
    print_section("Projection PCA")
    visualizer.plot_pca_2d(features_df, save_name="pca_projection.png")
    
    print("‚úÖ Visualisations sauvegard√©es dans:", Config.REPORTS_DIR)


def step_train_models(features_df):
    """
    √âtape 3: Entra√Ænement des mod√®les.
    """
    print_header("√âTAPE 3: ENTRA√éNEMENT DES MOD√àLES")
    
    trainer = ModelTrainer()
    
    # Pr√©parer les donn√©es
    print_section("Pr√©paration des donn√©es")
    X_train, X_val, X_test, y_train, y_val, y_test = trainer.prepare_data(features_df)
    
    # Entra√Æner tous les mod√®les
    print_section("Entra√Ænement")
    with Timer("Entra√Ænement de tous les mod√®les"):
        results_df = trainer.train_all_models(X_train, y_train, X_val, y_val)
    
    print("\nüìä R√©sultats de l'entra√Ænement:")
    print(results_df.to_string(index=False))
    
    # Sauvegarder le meilleur mod√®le
    print_section("Sauvegarde du mod√®le")
    trainer.save_model(trainer.best_model_name)
    
    return trainer, X_test, y_test


def step_evaluate(trainer, X_test, y_test):
    """
    √âtape 4: √âvaluation des mod√®les.
    """
    print_header("√âTAPE 4: √âVALUATION DES MOD√àLES")
    
    evaluator = Evaluator()
    visualizer = Visualizer()
    
    # √âvaluer le meilleur mod√®le
    best_model_name = trainer.best_model_name
    
    print_section(f"√âvaluation de {best_model_name}")
    y_pred = trainer.predict(best_model_name, X_test)
    
    # Afficher le rapport
    evaluator.print_evaluation(best_model_name, y_test, y_pred)
    
    # Visualisations
    print_section("Visualisation des r√©sultats")
    
    # Matrice de confusion
    evaluator.plot_confusion_matrix(
        y_test, y_pred, 
        normalize=True,
        title=f"Matrice de Confusion - {best_model_name}",
        save_name="confusion_matrix.png"
    )
    
    # Rapport de classification
    evaluator.plot_classification_report(
        y_test, y_pred,
        title=f"Rapport de Classification - {best_model_name}",
        save_name="classification_report.png"
    )
    
    # Comparer tous les mod√®les
    print_section("Comparaison des mod√®les")
    
    all_results = {}
    for model_name in trainer.trained_models.keys():
        y_pred_model = trainer.predict(model_name, X_test)
        metrics = evaluator.calculate_metrics(y_test, y_pred_model)
        all_results[model_name] = {'metrics': metrics}
    
    comparison_df = evaluator.compare_models(all_results)
    print("\nüìä Comparaison finale des mod√®les:")
    print(comparison_df.to_string(index=False))
    
    # Graphique de comparaison
    evaluator.plot_model_comparison(all_results, save_name="model_comparison.png")
    
    print("\n‚úÖ √âvaluation termin√©e!")
    print(f"   R√©sultats sauvegard√©s dans: {Config.REPORTS_DIR}")


def main():
    """
    Fonction principale - Pipeline complet.
    """
    # Parser les arguments
    parser = argparse.ArgumentParser(
        description="Classification des Genres Musicaux",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
    python main.py                    # Pipeline complet
    python main.py --step extract     # Extraction des features uniquement
    python main.py --step train       # Entra√Ænement uniquement
    python main.py --step evaluate    # √âvaluation uniquement
        """
    )
    
    parser.add_argument(
        '--step', 
        type=str, 
        choices=['extract', 'train', 'evaluate', 'all'],
        default='all',
        help="√âtape √† ex√©cuter (d√©faut: all)"
    )
    
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help="Graine al√©atoire (d√©faut: 42)"
    )
    
    args = parser.parse_args()
    
    # Afficher le header
    print_header("üéµ CLASSIFICATION DES GENRES MUSICAUX üéµ", "=", 60)
    
    # V√©rifier les d√©pendances
    print_section("V√©rification des d√©pendances")
    deps = check_dependencies()
    
    missing = [pkg for pkg, installed in deps.items() if not installed]
    if missing:
        print(f"\n‚ö†Ô∏è  Packages manquants: {missing}")
        print("   Installez-les avec: pip install -r requirements.txt")
        return
    
    # Cr√©er les r√©pertoires
    Config.create_directories()
    
    # Fixer la graine al√©atoire
    set_random_seed(args.seed)
    
    # Ex√©cuter les √©tapes
    if args.step in ['extract', 'all']:
        features_df = step_extract_features()
        if features_df is None:
            return
    else:
        # Charger les features existantes
        features_path = Config.DATA_PROCESSED / Config.FEATURES_FILE
        if features_path.exists():
            import pandas as pd
            features_df = pd.read_csv(features_path)
            print(f"‚úÖ Features charg√©es depuis: {features_path}")
        else:
            print(f"‚ùå Fichier features non trouv√©: {features_path}")
            print("   Ex√©cutez d'abord: python main.py --step extract")
            return
    
    if args.step in ['train', 'all']:
        if args.step == 'all':
            step_visualize(features_df)
        
        trainer, X_test, y_test = step_train_models(features_df)
    
    if args.step in ['evaluate', 'all']:
        if args.step == 'evaluate':
            # Charger le mod√®le
            trainer = ModelTrainer()
            X_train, X_val, X_test, y_train, y_val, y_test = trainer.prepare_data(features_df)
            
            # Chercher les mod√®les sauvegard√©s
            model_files = list(Config.MODELS_DIR.glob("*.joblib"))
            if model_files:
                for model_file in model_files:
                    trainer.load_model(model_file)
                trainer.best_model_name = list(trainer.trained_models.keys())[0]
            else:
                print("‚ùå Aucun mod√®le sauvegard√© trouv√©.")
                print("   Ex√©cutez d'abord: python main.py --step train")
                return
        
        step_evaluate(trainer, X_test, y_test)
    
    # R√©sum√© final
    print_header("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS ‚úÖ", "=", 60)
    print(f"""
üìÅ Fichiers g√©n√©r√©s:
    - Features: {Config.DATA_PROCESSED / Config.FEATURES_FILE}
    - Mod√®les : {Config.MODELS_DIR}
    - Figures : {Config.REPORTS_DIR}

üöÄ Prochaines √©tapes:
    1. Examiner les visualisations dans {Config.REPORTS_DIR}
    2. Analyser les erreurs de classification
    3. Optimiser les hyperparam√®tres si n√©cessaire
    4. Pr√©parer le rapport et la pr√©sentation
    """)


if __name__ == "__main__":
    main()
