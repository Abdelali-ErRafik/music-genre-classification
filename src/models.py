"""
Module des Mod√®les de Machine Learning
======================================

Ce module contient les d√©finitions et l'entra√Ænement des mod√®les
de classification pour la reconnaissance des genres musicaux.
"""

import numpy as np
import pandas as pd
import joblib
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from tqdm import tqdm
import warnings

# Scikit-learn
from sklearn.model_selection import (
    train_test_split, 
    cross_val_score, 
    GridSearchCV,
    StratifiedKFold
)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import (
    RandomForestClassifier, 
    GradientBoostingClassifier,
    AdaBoostClassifier,
    VotingClassifier
)
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.pipeline import Pipeline

from .config import Config

warnings.filterwarnings('ignore')


class ModelTrainer:
    """
    Classe pour entra√Æner et g√©rer les mod√®les de classification.
    
    Cette classe fournit des m√©thodes pour:
    - Pr√©parer les donn√©es pour l'entra√Ænement
    - Entra√Æner diff√©rents mod√®les de ML
    - Optimiser les hyperparam√®tres
    - Sauvegarder et charger les mod√®les
    
    Attributes:
        models: Dictionnaire des mod√®les disponibles
        scaler: StandardScaler pour normaliser les features
        label_encoder: LabelEncoder pour encoder les genres
    """
    
    def __init__(self):
        """Initialise le ModelTrainer avec les mod√®les par d√©faut."""
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.trained_models = {}
        self.best_model = None
        self.best_model_name = None
        
        # D√©finir les mod√®les disponibles
        self.models = self._get_default_models()
        
    def _get_default_models(self) -> Dict[str, Any]:
        """
        Retourne les mod√®les par d√©faut.
        
        Returns:
            Dictionnaire {nom: mod√®le}
        """
        return {
            'KNN': KNeighborsClassifier(n_neighbors=5),
            'SVM': SVC(kernel='rbf', C=10, gamma='scale', probability=True),
            'Random Forest': RandomForestClassifier(
                n_estimators=200, 
                max_depth=20,
                random_state=Config.RANDOM_STATE
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=Config.RANDOM_STATE
            ),
            'MLP': MLPClassifier(
                hidden_layer_sizes=(100, 50),
                activation='relu',
                max_iter=500,
                random_state=Config.RANDOM_STATE
            ),
            'Logistic Regression': LogisticRegression(
                max_iter=1000,
                random_state=Config.RANDOM_STATE
            ),
            'Decision Tree': DecisionTreeClassifier(
                max_depth=20,
                random_state=Config.RANDOM_STATE
            ),
            'Naive Bayes': GaussianNB(),
            'AdaBoost': AdaBoostClassifier(
                n_estimators=100,
                random_state=Config.RANDOM_STATE
            )
        }
    
    def prepare_data(self, df: pd.DataFrame,
                     test_size: float = 0.2,
                     val_size: float = 0.1) -> Tuple:
        """
        Pr√©pare les donn√©es pour l'entra√Ænement.
        
        Args:
            df: DataFrame avec les features et la colonne 'genre'
            test_size: Proportion pour le test
            val_size: Proportion pour la validation
            
        Returns:
            Tuple (X_train, X_val, X_test, y_train, y_val, y_test)
        """
        # S√©parer features et labels
        feature_cols = [c for c in df.columns 
                        if c not in ['filename', 'genre', 'filepath']]
        
        X = df[feature_cols].values
        y = df['genre'].values
        
        # Encoder les labels
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Premier split: train+val vs test
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y_encoded, 
            test_size=test_size,
            stratify=y_encoded,
            random_state=Config.RANDOM_STATE
        )
        
        # Second split: train vs val
        val_ratio = val_size / (1 - test_size)
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp,
            test_size=val_ratio,
            stratify=y_temp,
            random_state=Config.RANDOM_STATE
        )
        
        # Normaliser les features
        X_train = self.scaler.fit_transform(X_train)
        X_val = self.scaler.transform(X_val)
        X_test = self.scaler.transform(X_test)
        
        print(f"‚úÖ Donn√©es pr√©par√©es:")
        print(f"   - Entra√Ænement : {len(X_train)} √©chantillons")
        print(f"   - Validation   : {len(X_val)} √©chantillons")
        print(f"   - Test         : {len(X_test)} √©chantillons")
        print(f"   - Features     : {X_train.shape[1]}")
        print(f"   - Classes      : {len(self.label_encoder.classes_)}")
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def train_model(self, model_name: str, 
                    X_train: np.ndarray, 
                    y_train: np.ndarray,
                    X_val: Optional[np.ndarray] = None,
                    y_val: Optional[np.ndarray] = None) -> Dict:
        """
        Entra√Æne un mod√®le sp√©cifique.
        
        Args:
            model_name: Nom du mod√®le
            X_train: Features d'entra√Ænement
            y_train: Labels d'entra√Ænement
            X_val: Features de validation (optionnel)
            y_val: Labels de validation (optionnel)
            
        Returns:
            Dictionnaire avec les r√©sultats
        """
        if model_name not in self.models:
            raise ValueError(f"Mod√®le inconnu: {model_name}")
        
        print(f"üîÑ Entra√Ænement de {model_name}...")
        
        model = self.models[model_name]
        model.fit(X_train, y_train)
        
        # Calculer les scores
        train_score = model.score(X_train, y_train)
        val_score = model.score(X_val, y_val) if X_val is not None else None
        
        # Sauvegarder le mod√®le entra√Æn√©
        self.trained_models[model_name] = model
        
        results = {
            'model_name': model_name,
            'train_accuracy': train_score,
            'val_accuracy': val_score
        }
        
        print(f"   ‚úÖ Train Accuracy: {train_score:.4f}")
        if val_score:
            print(f"   ‚úÖ Val Accuracy  : {val_score:.4f}")
        
        return results
    
    def train_all_models(self, X_train: np.ndarray, y_train: np.ndarray,
                         X_val: np.ndarray, y_val: np.ndarray) -> pd.DataFrame:
        """
        Entra√Æne tous les mod√®les disponibles.
        
        Args:
            X_train: Features d'entra√Ænement
            y_train: Labels d'entra√Ænement
            X_val: Features de validation
            y_val: Labels de validation
            
        Returns:
            DataFrame avec les r√©sultats de tous les mod√®les
        """
        print("\n" + "=" * 50)
        print("ENTRA√éNEMENT DE TOUS LES MOD√àLES")
        print("=" * 50 + "\n")
        
        all_results = []
        
        for model_name in self.models.keys():
            try:
                results = self.train_model(model_name, X_train, y_train, X_val, y_val)
                all_results.append(results)
            except Exception as e:
                print(f"   ‚ùå Erreur pour {model_name}: {e}")
        
        # Cr√©er le DataFrame des r√©sultats
        results_df = pd.DataFrame(all_results)
        results_df = results_df.sort_values('val_accuracy', ascending=False)
        
        # Identifier le meilleur mod√®le
        self.best_model_name = results_df.iloc[0]['model_name']
        self.best_model = self.trained_models[self.best_model_name]
        
        print("\n" + "=" * 50)
        print(f"üèÜ Meilleur mod√®le: {self.best_model_name}")
        print(f"   Accuracy: {results_df.iloc[0]['val_accuracy']:.4f}")
        print("=" * 50)
        
        return results_df
    
    def cross_validate(self, model_name: str, 
                       X: np.ndarray, 
                       y: np.ndarray,
                       cv: int = 5) -> Dict:
        """
        Effectue une validation crois√©e pour un mod√®le.
        
        Args:
            model_name: Nom du mod√®le
            X: Features
            y: Labels
            cv: Nombre de folds
            
        Returns:
            Dictionnaire avec les scores de cross-validation
        """
        if model_name not in self.models:
            raise ValueError(f"Mod√®le inconnu: {model_name}")
        
        print(f"üîÑ Cross-validation pour {model_name} ({cv} folds)...")
        
        model = self.models[model_name]
        
        # Stratified K-Fold
        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=Config.RANDOM_STATE)
        
        scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')
        
        results = {
            'model_name': model_name,
            'cv_scores': scores,
            'cv_mean': np.mean(scores),
            'cv_std': np.std(scores)
        }
        
        print(f"   ‚úÖ CV Accuracy: {results['cv_mean']:.4f} (+/- {results['cv_std']:.4f})")
        
        return results
    
    def cross_validate_all(self, X: np.ndarray, y: np.ndarray,
                           cv: int = 5) -> pd.DataFrame:
        """
        Effectue une validation crois√©e pour tous les mod√®les.
        
        Args:
            X: Features (normalis√©es)
            y: Labels
            cv: Nombre de folds
            
        Returns:
            DataFrame avec les r√©sultats de cross-validation
        """
        print("\n" + "=" * 50)
        print(f"CROSS-VALIDATION ({cv} FOLDS)")
        print("=" * 50 + "\n")
        
        all_results = []
        
        for model_name in tqdm(self.models.keys(), desc="Cross-validation"):
            try:
                results = self.cross_validate(model_name, X, y, cv)
                all_results.append({
                    'model_name': results['model_name'],
                    'cv_mean': results['cv_mean'],
                    'cv_std': results['cv_std']
                })
            except Exception as e:
                print(f"   ‚ùå Erreur pour {model_name}: {e}")
        
        results_df = pd.DataFrame(all_results)
        results_df = results_df.sort_values('cv_mean', ascending=False)
        
        return results_df
    
    def hyperparameter_tuning(self, model_name: str,
                              X_train: np.ndarray,
                              y_train: np.ndarray,
                              param_grid: Optional[Dict] = None,
                              cv: int = 3) -> Dict:
        """
        Optimise les hyperparam√®tres d'un mod√®le.
        
        Args:
            model_name: Nom du mod√®le
            X_train: Features d'entra√Ænement
            y_train: Labels d'entra√Ænement
            param_grid: Grille de param√®tres (utilise les d√©fauts si None)
            cv: Nombre de folds
            
        Returns:
            Dictionnaire avec les meilleurs param√®tres
        """
        # Grilles de param√®tres par d√©faut
        default_grids = {
            'KNN': Config.KNN_PARAMS,
            'SVM': Config.SVM_PARAMS,
            'Random Forest': Config.RF_PARAMS,
            'Gradient Boosting': Config.GB_PARAMS,
            'MLP': Config.MLP_PARAMS
        }
        
        if param_grid is None:
            if model_name not in default_grids:
                print(f"‚ö†Ô∏è  Pas de grille par d√©faut pour {model_name}")
                return {}
            param_grid = default_grids[model_name]
        
        print(f"üîÑ Optimisation des hyperparam√®tres pour {model_name}...")
        
        model = self.models[model_name]
        
        grid_search = GridSearchCV(
            model, 
            param_grid, 
            cv=cv, 
            scoring='accuracy',
            n_jobs=-1,
            verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        
        results = {
            'model_name': model_name,
            'best_params': grid_search.best_params_,
            'best_score': grid_search.best_score_,
            'best_estimator': grid_search.best_estimator_
        }
        
        print(f"   ‚úÖ Meilleurs param√®tres: {results['best_params']}")
        print(f"   ‚úÖ Meilleur score: {results['best_score']:.4f}")
        
        # Mettre √† jour le mod√®le avec les meilleurs param√®tres
        self.models[model_name] = results['best_estimator']
        
        return results
    
    def create_ensemble(self, model_names: List[str],
                        voting: str = 'soft') -> VotingClassifier:
        """
        Cr√©e un ensemble de mod√®les.
        
        Args:
            model_names: Liste des noms de mod√®les √† combiner
            voting: Type de vote ('hard' ou 'soft')
            
        Returns:
            VotingClassifier
        """
        estimators = []
        for name in model_names:
            if name in self.trained_models:
                estimators.append((name, self.trained_models[name]))
            else:
                print(f"‚ö†Ô∏è  {name} non entra√Æn√©, ignor√©")
        
        if len(estimators) < 2:
            raise ValueError("Au moins 2 mod√®les entra√Æn√©s sont n√©cessaires")
        
        ensemble = VotingClassifier(estimators=estimators, voting=voting)
        
        print(f"‚úÖ Ensemble cr√©√© avec {len(estimators)} mod√®les ({voting} voting)")
        
        return ensemble
    
    def predict(self, model_name: str, X: np.ndarray) -> np.ndarray:
        """
        Fait des pr√©dictions avec un mod√®le entra√Æn√©.
        
        Args:
            model_name: Nom du mod√®le
            X: Features (doivent √™tre normalis√©es)
            
        Returns:
            Array des pr√©dictions
        """
        if model_name not in self.trained_models:
            raise ValueError(f"Mod√®le {model_name} non entra√Æn√©")
        
        return self.trained_models[model_name].predict(X)
    
    def predict_proba(self, model_name: str, X: np.ndarray) -> np.ndarray:
        """
        Retourne les probabilit√©s de pr√©diction.
        
        Args:
            model_name: Nom du mod√®le
            X: Features (doivent √™tre normalis√©es)
            
        Returns:
            Array des probabilit√©s par classe
        """
        if model_name not in self.trained_models:
            raise ValueError(f"Mod√®le {model_name} non entra√Æn√©")
        
        model = self.trained_models[model_name]
        
        if hasattr(model, 'predict_proba'):
            return model.predict_proba(X)
        else:
            raise ValueError(f"{model_name} ne supporte pas predict_proba")
    
    def decode_predictions(self, y_pred: np.ndarray) -> np.ndarray:
        """
        D√©code les pr√©dictions num√©riques en noms de genres.
        
        Args:
            y_pred: Array des pr√©dictions encod√©es
            
        Returns:
            Array des noms de genres
        """
        return self.label_encoder.inverse_transform(y_pred)
    
    def save_model(self, model_name: str, 
                   filepath: Optional[Path] = None) -> str:
        """
        Sauvegarde un mod√®le entra√Æn√©.
        
        Args:
            model_name: Nom du mod√®le
            filepath: Chemin de sauvegarde (optionnel)
            
        Returns:
            Chemin du fichier sauvegard√©
        """
        if model_name not in self.trained_models:
            raise ValueError(f"Mod√®le {model_name} non entra√Æn√©")
        
        if filepath is None:
            filepath = Config.MODELS_DIR / f"{model_name.lower().replace(' ', '_')}.joblib"
        
        # Sauvegarder le mod√®le, le scaler et le label encoder
        save_dict = {
            'model': self.trained_models[model_name],
            'scaler': self.scaler,
            'label_encoder': self.label_encoder
        }
        
        joblib.dump(save_dict, filepath)
        print(f"üíæ Mod√®le sauvegard√©: {filepath}")
        
        return str(filepath)
    
    def load_model(self, filepath: Path) -> str:
        """
        Charge un mod√®le sauvegard√©.
        
        Args:
            filepath: Chemin du fichier
            
        Returns:
            Nom du mod√®le charg√©
        """
        save_dict = joblib.load(filepath)
        
        model_name = filepath.stem.replace('_', ' ').title()
        self.trained_models[model_name] = save_dict['model']
        self.scaler = save_dict['scaler']
        self.label_encoder = save_dict['label_encoder']
        
        print(f"üìÇ Mod√®le charg√©: {model_name}")
        
        return model_name
    
    def get_feature_importance(self, model_name: str) -> Optional[pd.DataFrame]:
        """
        Retourne l'importance des features pour les mod√®les qui le supportent.
        
        Args:
            model_name: Nom du mod√®le
            
        Returns:
            DataFrame avec l'importance des features, ou None
        """
        if model_name not in self.trained_models:
            return None
        
        model = self.trained_models[model_name]
        
        if hasattr(model, 'feature_importances_'):
            importance = model.feature_importances_
            return pd.DataFrame({
                'importance': importance
            }).sort_values('importance', ascending=False)
        
        return None
    
    def print_models_summary(self):
        """Affiche un r√©sum√© des mod√®les disponibles et entra√Æn√©s."""
        print("\n" + "=" * 50)
        print("R√âSUM√â DES MOD√àLES")
        print("=" * 50)
        
        print("\nüìã Mod√®les disponibles:")
        for name in self.models.keys():
            status = "‚úÖ Entra√Æn√©" if name in self.trained_models else "‚¨ú Non entra√Æn√©"
            print(f"   - {name}: {status}")
        
        if self.best_model_name:
            print(f"\nüèÜ Meilleur mod√®le: {self.best_model_name}")
        
        print("=" * 50)


# Test du module
if __name__ == "__main__":
    trainer = ModelTrainer()
    trainer.print_models_summary()
